{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "import numpy as np\n",
    "import isodate\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwid\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "GETTING DATA IN YOUTUBE"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"YOUTUBE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UCqaQzGvnFzaEPFx-f326pog', \n",
    "               #More channels here\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get credentials and create an API client\n",
    "youtube = build(\n",
    "    'youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id = ','.join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # loop through items:\n",
    "    for item in response['items']:\n",
    "        data = {'Channel Name': item['snippet']['title'],\n",
    "                'Subscribers': item['statistics']['subscriberCount'],\n",
    "                'Views': item['statistics']['viewCount'],\n",
    "                'Total Video': item['statistics']['videoCount'],\n",
    "                'Playlist ID': item['contentDetails']['relatedPlaylists']['uploads']     \n",
    "        }\n",
    "        all_data.append(data)\n",
    "    return(pd.DataFrame(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_stats = get_channel_stats(youtube, channel_ids)\n",
    "channel_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING VIDEO ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id = 'UUqaQzGvnFzaEPFx-f326pog'\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "\n",
    "    request = youtube.playlistItems().list(\n",
    "                part=\"contentDetails\",\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = 50)\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "    \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "    \n",
    "    while more_pages:\n",
    "        if next_page_token is None:\n",
    "            more_pages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                        part=\"contentDetails\",\n",
    "                        playlistId = playlist_id,\n",
    "                        maxResults = 50,\n",
    "                        pageToken = next_page_token)\n",
    "            response = request.execute()\n",
    "        \n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "        \n",
    "            next_page_token = response.get('nextPageToken')\n",
    "    \n",
    "    \n",
    "    return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = get_video_ids(youtube, playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING EACH VIDEO'S DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_ids):  \n",
    "\n",
    "    all_video_info = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "                part=\"snippet,contentDetails,statistics\", \n",
    "                id = ','.join(video_ids[i:i+50])\n",
    "            )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet':['title', 'tags', 'publishedAt'],\n",
    "                            'statistics': ['viewCount', 'likeCount' , 'commentCount'],\n",
    "                            'contentDetails':['duration', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_ids'] = video['id']\n",
    "            \n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "            \n",
    "            all_video_info.append(video_info)\n",
    "        \n",
    "    return pd.DataFrame(all_video_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df = get_video_details(youtube, video_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.drop_duplicates(subset = 'video_ids',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.drop(columns=['video_ids', 'caption'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_iso_to_normal(x):\n",
    "    datetime_obj = datetime.fromisoformat(x)\n",
    "    return datetime_obj.strftime('%Y-%m-%d %H:%M:%S %a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df['publishedAt'] = video_df['publishedAt'].apply(converting_iso_to_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_duration(x):\n",
    "    duration = isodate.parse_duration(x)\n",
    "    return duration.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df['duration'] = video_df['duration'].apply(converting_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['viewCount', 'likeCount', 'commentCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df[numeric_columns] = video_df[numeric_columns].apply(pd.to_numeric, axis=1, errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.drop(columns='tags', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df[['Date','Time', 'Weekday']] = video_df['publishedAt'].str.split(n = 3, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.drop(columns='publishedAt', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.drop(columns=['Time', 'Weekday'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING DATAFRAMES FOR EACH VIDEO TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING TEU TRY DATAFRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teu_try_df = video_df.loc[video_df['title'].str.contains('Táº¾U TRY')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teu_try_df.to_excel('D:/teu_try_df.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING SHORTS DATAFRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df = video_df.loc[video_df['title'].str.contains('short')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df.to_excel('D:/short.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING DAU TEU DATAFRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dau_teu_df = video_df.loc[video_df['title'].str.contains('Äáº¤U Táº¾U')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dau_teu_df.to_excel('D:/dau_teu.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING UNG TAC DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ung_tac_df = video_df.loc[video_df['title'].str.contains('Táº¾U á»¨NG TÃC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ung_tac_df.to_excel('D:/ung_tac.xlsx', index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING SPECIAL DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_df = video_df.loc[video_df['title'].str.contains('SPECIAL') | video_df['title'].str.contains('Táº¾U QUÃN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING SPECIAL DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_df = special_df[~special_df['title'].str.contains('#[1-5]', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDING COMEDIANS TO EACH VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_df[\"Comedian\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_df.loc[79, 'Comedian'] = 'Nhi VÃµ, Minh Ti, PhÆ°Æ¡ng Nam, Trá»ng Phan, Uy LÃª'\n",
    "special_df.loc[99, 'Comedian'] = 'Trá»ng Phan, Trung Coffee, PhÆ°Æ¡ng Nam, Minh Ti'     \n",
    "special_df.loc[136, 'Comedian'] = 'Nhi VÃµ, Trung Coffee, Trá»ng Phan, PhÆ°Æ¡ng Nam'     \n",
    "special_df.loc[163, 'Comedian'] = 'Trung Coffee, Minh Ti, TÃ¹ng BT, Trá»ng Phan, PhÆ°Æ¡ng Nam'     \n",
    "special_df.loc[220, 'Comedian'] = 'PhÆ°Æ¡ng Nam, Trá»ng Phan, Trung Coffee, Minh Ti, Uy LÃª'     \n",
    "special_df.loc[234, 'Comedian'] = 'Minh Ti, Trung Coffee, Thanh, Uy Nguyá»n, Trá»ng Phan, TÃ¹ng BT, Anh KhÃ´i, PhÆ°Æ¡ng Nam, Chaiyo ThÆ°Æ¡ng, Uy LÃª'\n",
    "special_df.loc[244, 'Comedian'] = 'Uy LÃª, Anh KhÃ´i, TÃ¹ng BT, PhÆ°Æ¡ng Nam'     \n",
    "special_df.loc[245, 'Comedian'] = 'Minh Ti, Chaiyo ThÆ°Æ¡ng, Uy Nguyá»n, Trá»ng Phan'     \n",
    "special_df.loc[254, 'Comedian'] = 'Trá»ng Phan, Anh KhÃ´i, PhÆ°Æ¡ng Nam, Uy LÃª'     \n",
    "special_df.loc[257, 'Comedian'] = 'Uy LÃª, Uy Nguyá»n, PhÆ°Æ¡ng Nam, Chaiyo ThÆ°Æ¡ng, Uy LÃª, Minh Ti'     \n",
    "special_df.loc[260, 'Comedian'] = 'Trá»ng Phan, Uy LÃª, Minh Ti'     \n",
    "special_df.loc[266, 'Comedian'] = 'Trá»ng Phan, Anh KhÃ´i, Minh Ti, Thanh, PhÆ°Æ¡ng Nam'     \n",
    "special_df.loc[272, 'Comedian'] = 'Uy LÃª, TÃ¹ng BT, Minh Ti, Trá»ng Phan, PhÆ°Æ¡ng Nam'                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_df.rename(columns={'viewCount' : 'View'}, inplace = True)\n",
    "special_df.rename(columns={'likeCount' : 'Like'}, inplace = True)\n",
    "special_df.rename(columns={'commentCount' : 'Comment'}, inplace = True)\n",
    "special_df.rename(columns={'duration' : 'Duration'}, inplace = True)\n",
    "special_df.rename(columns={'title' : 'Title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING MODIFIED SPECIAL DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_data = []\n",
    "\n",
    "for index, row in special_df.iterrows():\n",
    "    comedians = row['Comedian'].split(',')\n",
    "    \n",
    "    for comedian in comedians:\n",
    "        new_row = {\n",
    "            'Title': row['Title'],\n",
    "            'View': row['View'],\n",
    "            'Like': row['Like'],\n",
    "            'Comment': row['Comment'],\n",
    "            'Duration': row['Duration'],\n",
    "            'Date': row['Date'],\n",
    "            'Comedian': comedian.strip()\n",
    "        }\n",
    "        modified_data.append(new_row)\n",
    "modified_df = pd.DataFrame(modified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_df.to_excel('D:/modified_special.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_df.to_excel(\"D:/SaiGon_Teu_Special.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.to_excel(\"D:/All_SaiGon_Teu.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING HAI DOC THOAI DATAFRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = video_df.loc[video_df['title'].str.lower().str.contains('hÃ i Äá»c thoáº¡i')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING HAI DOC THOAI DATAFRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special = df1['title'].str.contains('SPECIAL')\n",
    "df1.drop(df1[special].index, inplace = True)\n",
    "short = df1['title'].str.contains('#Shorts')\n",
    "df1.drop(df1[short].index, inplace = True)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop([153, 156, 158, 160, 181, 251, 281], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1['title'].str.contains('KhÃ¡ch Má»i'), df1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df1.iterrows():\n",
    "    if 'KhÃ¡ch Má»i Saigon Táº¿u' in row['title']:\n",
    "        df1.at[index, 'title'] = row['title'].replace('HÃI Äá»C THOáº I - ', '')\n",
    "        df1.at[index, 'title'] = df1.at[index, 'title'].replace(' - KhÃ¡ch Má»i Saigon Táº¿u', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df1.iterrows():\n",
    "    if '| HÃ i Äá»c Thoáº¡i' in row['title']:                \n",
    "        df1.at[index, 'title'] = row['title'].replace(' | HÃ i Äá»c Thoáº¡i Saigon Táº¿u', '')\n",
    "        df1.at[index, 'title'] = df1.at[index, 'title'].replace(' Saigon Táº¿u | HÃ i Äá»c Thoáº¡i', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[29 , 'title'] = 'Happy BÃ­t Táº¿t - PhÆ°Æ¡ng Nam'\n",
    "df1.loc[16 , 'title'] = 'Thá»i Trang CÃ¢u Há»i - Huá»³n Khanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df1.iterrows():\n",
    "    if 'HÃI Äá»C THOáº I' in row['title']:\n",
    "        df1.at[index, 'title'] = row['title'].replace('HÃI Äá»C THOáº I - ', '')\n",
    "        df1.at[index, 'title'] = df1.at[index, 'title'].replace(' Saigon Táº¿u', '')\n",
    "        df1.at[index, 'title'] = df1.at[index, 'title'].replace('HÃI Äá»C THOáº I PURGATORY - ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formating(x):\n",
    "    if x.count('-') >= 2:\n",
    "        last_index = x.rfind('-')\n",
    "        x = x.replace('-', ' ', x.count('-'))\n",
    "        x = x[:last_index] + '-' + x[last_index+1:]\n",
    "    return x\n",
    "df1['title'] = df1['title'].apply(formating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['Title', 'Comedian']] = df1['title'].str.split('-', n = 2, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns = 'title', inplace = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1['Comedian'] == '', df1.columns]\n",
    "df1.loc[140, 'Comedian'] = 'Uy LÃª'\n",
    "df1.loc[205, 'Comedian'] = 'Uy LÃª'\n",
    "df1.loc[291, 'Comedian'] = 'TÃ¹ng BT'\n",
    "df1.loc[df1['Comedian'] == '', df1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns = 'title', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'viewCount' : 'View'}, inplace = True)\n",
    "df1.rename(columns={'likeCount' : 'Like'}, inplace = True)\n",
    "df1.rename(columns={'commentCount' : 'Comment'}, inplace = True)\n",
    "df1.rename(columns={'duration' : 'Duration'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1['Comedian'].str.contains('Quá»c KhÃ¡nh'), df1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['Title', 'Comedian', 'viewCount', 'likeCount', 'commentCount', 'duration', 'Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Comedian'] = df1['Comedian'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Comedian'] = df1['Comedian'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space(x):\n",
    "    space_count = x.count(' ')\n",
    "    if space_count >= 2:\n",
    "        x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Comedian'] = df1['Comedian'].apply(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Title'] = video_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel(\"D:/SaiGon_Teu.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
